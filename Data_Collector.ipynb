{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collector for Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file includes essential imports and functions required for data collection to train the gesture recognition model. It is intended to be executed once or when a sufficient amount of data has been gathered. Running this code facilitates the acquisition of the necessary training data for subsequent model development and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = np.array([\"minimize\", \"switch\", \"volume_down\", \"volume_up\"])\n",
    "vids = 30\n",
    "frames = 30\n",
    "data = os.path.join(\"ges_rec_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gesture in gestures:\n",
    "    for video in range(1, vids + 1):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(data, gesture, str(video)))\n",
    "        except FileExistsError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark_values(_results):\n",
    "    face_vals = np.array([[val.x, val.y, val.z] for val in _results.face_landmarks.landmark]).flatten() if _results.face_landmarks else np.zeros(1404)\n",
    "    left_hand_vals = np.array([[val.x, val.y, val.z] for val in _results.left_hand_landmarks.landmark]).flatten() if _results.left_hand_landmarks else np.zeros(63)\n",
    "    right_hand_vals = np.array([[val.x, val.y, val.z] for val in _results.right_hand_landmarks.landmark]).flatten() if _results.right_hand_landmarks else np.zeros(63)\n",
    "\n",
    "    return np.concatenate((face_vals, left_hand_vals, right_hand_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    exit_flag = False\n",
    "    for gesture in gestures:\n",
    "        for video in range(1, vids + 1):\n",
    "            if video == 30:\n",
    "                        cv2.putText(image, 'LAST VIDEO FOR {}. SWITCH TO NEXT GESTURE.'.format(gesture), (800, 450), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                        cv2.imshow('MediaPipe Holistic', image)\n",
    "                        cv2.waitKey(5000)\n",
    "            for frame in range(1, frames + 1):\n",
    "                success, image = cap.read()\n",
    "                if not success:\n",
    "                    print(\"Ignoring empty camera frame.\")\n",
    "                    # If loading a video, use 'break' instead of 'continue'.\n",
    "                    continue\n",
    "\n",
    "                # To improve performance, optionally mark the image as not writeable to\n",
    "                # pass by reference.\n",
    "                image.flags.writeable = False\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                results = holistic.process(image)\n",
    "\n",
    "                # Draw landmark annotation on the image.\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, landmark_drawing_spec=None, connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style())\n",
    "                mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "                \n",
    "                if frame == 1:\n",
    "                    cv2.putText(image, 'GESTURE: {}. GET READY'.format(gesture), (800, 450), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, 'VIDEO: {}'.format(video), (170, 50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    cv2.imshow('MediaPipe Holistic', image)\n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.imshow('MediaPipe Holistic', image)\n",
    "                    cv2.putText(image, 'VIDEO: {}'.format(video), (170, 50), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                # Collect landmark values\n",
    "                landmarks = get_landmark_values(results)\n",
    "                folder_path = os.path.join(data, gesture, str(video), str(frame))\n",
    "                np.save(folder_path, landmarks)\n",
    "                \n",
    "                # Exit out of webcam by pressing q\n",
    "                if cv2.waitKey(1) == ord('q'):\n",
    "                    exit_flag = True\n",
    "                    break\n",
    "            if exit_flag:\n",
    "                break\n",
    "        if exit_flag:\n",
    "            break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
